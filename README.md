# AI safety

## Open letters

• [Statement on Superintelligence (2025)](https://superintelligence-statement.org)

• [Pause Giant AI Experiments: An Open Letter (2023)](https://futureoflife.org/open-letter/pause-giant-ai-experiments)

• [Statement on AI Risk (2023)](https://aistatement.com)

## Talks

• [*Will AI outsmart human intelligence?*](https://www.youtube.com/watch?v=IkdziSLYzHw) | Geoffrey Hinton (The Royal Institution, 2025)

• [*The catastrophic risks of AI  — and a safer path*](https://www.youtube.com/watch?v=qe9QSCF-d88) | Yoshua Bengio (TED, 2025)

## Books

• [*If Anyone Builds It, Everyone Dies*](https://ifanyonebuildsit.com) | Eliezer Yudkowsky & Nate Soares (2025)

## Blogs

• [Yoshua Bengio](https://yoshuabengio.org)

## Scientific publications

• [*Managing extreme AI risks amid rapid progress*](https://arxiv.org/pdf/2310.17688) | Yoshua Bengio et al. Science, 384(6698):842–845, 2024.

## Non-profit organizations

• [Bulletin of the Atomic Scientists](https://thebulletin.org/disruptive-technologies/)

• [AI Futures Project](https://ai-futures.org)

• [Forethought](https://www.forethought.org)

• [Center for AI Safety](https://safe.ai)

• [LawZero](https://lawzero.org)

• [Centre pour la Sécurité de l'IA](https://www.securite-ia.fr)

# AI history

## Semantic papers

[*Computing machinery and intelligence*](https://ebiquity.umbc.edu/_file_directory_/papers/1389.pdf) | Alan M. Turing. Mind, 59(236):33–60, 1950.

## Proposals

• [*Dartmouth Summer Research Project on Artificial Intelligence*](https://www-formal.stanford.edu/jmc/history/dartmouth.pdf) | John McCarty, Marvin Minsky, Nathaniel Rochester, Claude Shannon (Dartmouth College, 1955)

• [*Summer Vision Project*](https://dspace.mit.edu/bitstream/handle/1721.1/6125/AIM-100.pdf) | Seymour Papert (MIT, 1966)

## Talks

• [*Lighthill Controversy debate*](https://www.aiai.ed.ac.uk/events/lighthill1973) | Sir James Lighthill, Donald Michie, Richard Gregory, John McCarthy (Royal Institution, BBC, 1973)
